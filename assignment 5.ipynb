{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.055*\"great\" + 0.055*\"action\" + 0.055*\"sinek\" + 0.055*\"simon\" + 0.055*\"leaders\" + 0.055*\"inspire\" + 0.011*\"shonda\" + 0.011*\"rhimes\" + 0.011*\"hum\" + 0.011*\"year\"'), (1, '0.057*\"stroke\" + 0.031*\"bolte\" + 0.031*\"jill\" + 0.031*\"description\" + 0.031*\"insight\" + 0.031*\"recovery\" + 0.031*\"vivid\" + 0.031*\"taylor\" + 0.031*\"poetic\" + 0.031*\"genius\"'), (2, '0.067*\"surprising\" + 0.067*\"happiness\" + 0.037*\"power\" + 0.037*\"gilbert\" + 0.037*\"level\" + 0.037*\"systems\" + 0.037*\"james\" + 0.037*\"habits\" + 0.037*\"small\" + 0.037*\"clear\"'), (3, '0.049*\"creativity\" + 0.049*\"vulnerability\" + 0.027*\"robinson\" + 0.027*\"ken\" + 0.027*\"kill\" + 0.027*\"schools\" + 0.027*\"education\" + 0.027*\"literacy\" + 0.027*\"important\" + 0.027*\"brené\"')]\n",
      "[(3, 0), (0, 1), (3, 2), (3, 3), (1, 4), (1, 5), (2, 6), (1, 7), (3, 8), (2, 9)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "from nltk import word_tokenize, pos_tag, download\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "download('punkt')\n",
    "download('averaged_perceptron_tagger')\n",
    "\n",
    "# Sample data\n",
    "transcripts = [\n",
    "    \"\"\"Brené Brown: The power of vulnerability.\\nVulnerability is not weakness; it’s our greatest measure of courage.\"\"\",\n",
    "    \"\"\"Simon Sinek: How Great Leaders Inspire Action.\\nPeople don’t buy what you do; they buy why you do it.\"\"\",\n",
    "    \"\"\"Ken Robinson: Do Schools Kill Creativity?\\nCreativity is as important in education as literacy.\"\"\",\n",
    "    \"\"\"Amy Cuddy: Your Body Language Shapes Who You Are.\\nFake it till you become it.\"\"\",\n",
    "    \"\"\"Shonda Rhimes: My Year of Saying Yes to Everything.\\nThe hum is gone, and I wanted it back.\"\"\",\n",
    "    \"\"\"Jill Bolte Taylor: My Stroke of Insight.\\nHer vivid, poetic description of the stroke and recovery.\"\"\",\n",
    "    \"\"\"Dan Gilbert: The Surprising Science of Happiness.\\nSynthetic happiness shows how people adapt.\"\"\",\n",
    "    \"\"\"Elizabeth Gilbert: Your Elusive Creative Genius.\\nCreativity as a partnership with an external source.\"\"\",\n",
    "    \"\"\"Tony Robbins: Why We Do What We Do.\\nSix core human needs shape our actions.\"\"\",\n",
    "    \"\"\"James Clear: Atomic Habits: The Surprising Power of Small Changes.\\nYou fall to the level of your systems.\"\"\"\n",
    "]\n",
    "\n",
    "data = pd.DataFrame({\"transcript\": transcripts})\n",
    "\n",
    "# Function to extract nouns\n",
    "def nouns(text):\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)]\n",
    "    return ' '.join(all_nouns)\n",
    "\n",
    "# Function to extract nouns and adjectives\n",
    "def nouns_adj(text):\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)]\n",
    "    return ' '.join(nouns_adj)\n",
    "\n",
    "# Apply noun extraction\n",
    "data_nouns = pd.DataFrame(data.transcript.apply(nouns), columns=['transcript'])\n",
    "\n",
    "# Apply noun and adjective extraction\n",
    "data_nouns_adj = pd.DataFrame(data.transcript.apply(nouns_adj), columns=['transcript'])\n",
    "\n",
    "# Stop words\n",
    "add_stop_words = ['like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people',\n",
    "                  'youre', 'got', 'gonna', 'time', 'think', 'yeah', 'said']\n",
    "stop_words = list(text.ENGLISH_STOP_WORDS.union(add_stop_words))\n",
    "\n",
    "# CountVectorizer for nouns\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvn.fit_transform(data_nouns.transcript)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names_out())\n",
    "\n",
    "# CountVectorizer for nouns and adjectives\n",
    "cvna = CountVectorizer(stop_words=stop_words, max_df=.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.transcript)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names_out())\n",
    "\n",
    "# Create gensim corpus for nouns and adjectives\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())\n",
    "\n",
    "# LDA Model for nouns and adjectives\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=80)\n",
    "\n",
    "# Print topics\n",
    "print(ldana.print_topics())\n",
    "\n",
    "# Assign topics to documents\n",
    "corpus_transformed = ldana[corpusna]\n",
    "results = list(zip([a for a, _ in [max(doc, key=lambda x: x[1]) for doc in corpus_transformed]], data.index))\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
